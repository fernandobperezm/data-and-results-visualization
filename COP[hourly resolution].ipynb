{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from math import cos, sin, exp, sqrt, pi, e\n",
    "\n",
    "from src.OspitalettoDataset import OspitalettoDataset\n",
    "from src.NOAA2010Dataset import NOAA2010Dataset\n",
    "from src.InsPireDataset import InsPireDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants to be used across the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT_evap': 8.0,\n",
       " 'Tdhw': 55.0,\n",
       " 'Tmax_i': 60.0,\n",
       " 'Tmin_i': 45.0,\n",
       " 'Ts1': 23.0,\n",
       " 'Ts2': 29.0,\n",
       " 'depth_aquifer': 30.0,\n",
       " 'n_buildings_MFH': 1600.0,\n",
       " 'n_buildings_SFH': 0.0,\n",
       " 's1_schedule': [[0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0]],\n",
       " 's2_schedule': [[1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0]]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_values_path = os.path.join(\".\", \"data\", \"simulation_values.json\")    \n",
    "with open(simulation_values_path, \"r\") as f:\n",
    "    simulation_values = json.load(f)\n",
    "    \n",
    "simulation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press 1 if you want to reload previous simulation values 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Tmin_i=45.0\n",
      "* Tmax_i=60.0\n",
      "* Tdhw=55.0\n",
      "* Ts1=23.0\n",
      "* Ts2=29.0\n",
      "* DT_evap=8.0\n",
      "* n_buildings_SFH=0.0\n",
      "* n_buildings_MFH=1600.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_or_write_new = int(input(\"Press 1 if you want to reload previous simulation values\"))\n",
    "\n",
    "if load_or_write_new == 1:    \n",
    "    Tmin_i = simulation_values[\"Tmin_i\"]\n",
    "    Tmax_i = simulation_values[\"Tmax_i\"]\n",
    "\n",
    "    Tdhw = simulation_values[\"Tdhw\"]\n",
    "\n",
    "    Ts1 = simulation_values[\"Ts1\"]\n",
    "    Ts2 = simulation_values[\"Ts2\"]\n",
    "\n",
    "    DT_evap = simulation_values[\"DT_evap\"]\n",
    "    \n",
    "    n_buildings_SFH = simulation_values[\"n_buildings_SFH\"]\n",
    "    n_buildings_MFH = simulation_values[\"n_buildings_MFH\"]\n",
    "    \n",
    "else:\n",
    "    # Min and Max temperatures to be received by the user.\n",
    "    # Values [40,...,60]\n",
    "    Tmin_i = float(input(\"Enter min setpoint temperature: \"))\n",
    "    Tmax_i = float(input(\"Enter max setpoint temperature: \"))\n",
    "\n",
    "    # Domestic hot water temperature.\n",
    "    # Values [45,...,55]\n",
    "    Tdhw = float(input(\"Enter domestic hot water temperature: \"))\n",
    "\n",
    "    # Our model supposes that the system has two different sources of heat.\n",
    "    # Values [20,...,30]\n",
    "    Ts1 = float(input(\"Temperature of source 1: \"))\n",
    "    Ts2 = float(input(\"Temperature of source 2: \"))\n",
    "\n",
    "    # difference in temperature between the supply (system->heat->house) and return (house -> heat -> system) pipes\n",
    "    # Values [1,...,10]\n",
    "    DT_evap = float(input(\"Temperature difference among the supply and return pipes: \"))\n",
    "    \n",
    "    # For the data visualization course, we will select 0 SFH & 1600 MFH buildings, which will cover an area of 1 km2\n",
    "    n_buildings_SFH =float(input(\"Enter the number of SFH buildings: #\"))\n",
    "    n_buildings_MFH=float(input(\"Enter the number of MFH buildings:#\"))\n",
    "    \n",
    "print(f\"* {Tmin_i=}\\n\"\n",
    "      f\"* {Tmax_i=}\\n\"\n",
    "      f\"* {Tdhw=}\\n\"\n",
    "      f\"* {Ts1=}\\n\"\n",
    "      f\"* {Ts2=}\\n\"\n",
    "      f\"* {DT_evap=}\\n\"\n",
    "      f\"* {n_buildings_SFH=}\\n\"\n",
    "      f\"* {n_buildings_MFH=}\\n\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load Sources working hours\n",
    "\n",
    "The file must be a boolean matrix $W$ of $24 x 7$. The rows represent the hours in a day, and the columns represent the days in the week. For all $i \\in \\{0,...,23\\}$ and $j \\in \\{0,..., 6\\}$ we have that $w_{i,j} \\in \\{0, 1\\}$, where $w_{i,j} = 0$ means that the source doesn't produce energy at that hour $i$ on that day $j$. Similarly, $w_{i,j} = 1$ means that the source produces energy at that hour $i$ on that day $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* s1_schedule_path='./data/private/s1_source_fake_schedule.xlsx'\n",
      "* s1_schedule=array([[0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0]])\n",
      "* s1_schedule[6,1]=0\n",
      "* s1_schedule[7,1]=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1_schedule_path = os.path.join(\".\", \"data\", \"private\", \"s1_source_fake_schedule.xlsx\")\n",
    "if load_or_write_new == 1:\n",
    "    s1_schedule = np.array(simulation_values[\"s1_schedule\"])\n",
    "else:    \n",
    "    s1_schedule = pd.read_excel(s1_schedule_path, index_col=\"Time\").to_numpy()\n",
    "\n",
    "print(f\"* {s1_schedule_path=}\\n\"\n",
    "      f\"* {s1_schedule=}\\n\"\n",
    "      f\"* {s1_schedule[6,1]=}\\n\" # Tuesdays are closed at 6 (equal to 0)\n",
    "      f\"* {s1_schedule[7,1]=}\\n\") # but open are 7 (equal to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* s2_schedule_path='./data/private/s2_source_fake_schedule.xlsx'\n",
      "* s2_schedule=array([[1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 0, 0, 1, 1, 1, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0]])\n",
      "* s2_schedule[15,1]=1\n",
      "* s2_schedule[16,1]=0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2_schedule_path = os.path.join(\".\", \"data\", \"private\", \"s2_source_fake_schedule.xlsx\")\n",
    "if load_or_write_new == 1:\n",
    "    s2_schedule = np.array(simulation_values[\"s2_schedule\"])\n",
    "else: \n",
    "    s2_schedule = pd.read_excel(s2_schedule_path, index_col=\"Time\").to_numpy()\n",
    "\n",
    "print(f\"* {s2_schedule_path=}\\n\"\n",
    "      f\"* {s2_schedule=}\\n\"\n",
    "      f\"* {s2_schedule[15,1]=}\\n\" # Tuesdays are closed at 15 (equal to 0)\n",
    "      f\"* {s2_schedule[16,1]=}\\n\") # but open are 16 (equal to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take note of the values for the current simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT_evap': 8.0,\n",
       " 'Tdhw': 55.0,\n",
       " 'Tmax_i': 60.0,\n",
       " 'Tmin_i': 45.0,\n",
       " 'Ts1': 23.0,\n",
       " 'Ts2': 29.0,\n",
       " 'depth_aquifer': 30.0,\n",
       " 'n_buildings_MFH': 1600.0,\n",
       " 'n_buildings_SFH': 0.0,\n",
       " 's1_schedule': [[0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0]],\n",
       " 's2_schedule': [[1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0]]}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_values[\"Tmin_i\"] = Tmin_i\n",
    "simulation_values[\"Tmax_i\"] = Tmax_i\n",
    "simulation_values[\"Tdhw\"] = Tdhw\n",
    "simulation_values[\"Ts1\"] = Ts1\n",
    "simulation_values[\"Ts2\"] = Ts2\n",
    "simulation_values[\"DT_evap\"] = DT_evap\n",
    "simulation_values[\"s1_schedule\"] = s1_schedule.tolist()\n",
    "simulation_values[\"s2_schedule\"] = s2_schedule.tolist()\n",
    "simulation_values[\"n_buildings_SFH\"] = n_buildings_SFH\n",
    "simulation_values[\"n_buildings_MFH\"] = n_buildings_MFH\n",
    "simulation_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ospitaletto', 'miami_florida', 'fresno_california', 'olympia_washington', 'rochester_newyork', 'london_uk', 'madrid_spain', 'rome_italy', 'stuttgart_germany'])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ospitaletto2019 = OspitalettoDataset()\n",
    "noaa2010Dataset = NOAA2010Dataset()\n",
    "insPireDataset = InsPireDataset()\n",
    "\n",
    "AVAILABLE_DATASETS = dict()\n",
    "AVAILABLE_DATASETS.update(ospitaletto2019.load_processed_data())\n",
    "AVAILABLE_DATASETS.update(noaa2010Dataset.load_processed_data())\n",
    "AVAILABLE_DATASETS.update(insPireDataset.load_processed_data())\n",
    "AVAILABLE_DATASETS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ospitaletto'"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_work = \"ospitaletto\"\n",
    "dataset_to_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_temp</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>month</th>\n",
       "      <th>hourofyear</th>\n",
       "      <th>air_temp_fit</th>\n",
       "      <th>ground_temp</th>\n",
       "      <th>aquifer_temp</th>\n",
       "      <th>space_heating_temp</th>\n",
       "      <th>hot_water_temp</th>\n",
       "      <th>user_temp</th>\n",
       "      <th>source1_temp</th>\n",
       "      <th>source2_temp</th>\n",
       "      <th>net_temp</th>\n",
       "      <th>COP</th>\n",
       "      <th>E_loss_s</th>\n",
       "      <th>E_loss_r</th>\n",
       "      <th>E_loss_tot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.821755</td>\n",
       "      <td>9.626282</td>\n",
       "      <td>15.365495</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.975779</td>\n",
       "      <td>0.030747</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.041495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.818987</td>\n",
       "      <td>9.622604</td>\n",
       "      <td>15.365495</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.975779</td>\n",
       "      <td>0.030755</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.041510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>9.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.816225</td>\n",
       "      <td>9.618929</td>\n",
       "      <td>15.365495</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.975779</td>\n",
       "      <td>0.030762</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.041524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>9.183333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.813468</td>\n",
       "      <td>9.615257</td>\n",
       "      <td>15.365495</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.975779</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.041539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>8.916667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4.810717</td>\n",
       "      <td>9.611587</td>\n",
       "      <td>15.365495</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>40.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.975779</td>\n",
       "      <td>0.030777</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.041554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 20:00:00</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>364</td>\n",
       "      <td>12</td>\n",
       "      <td>8733</td>\n",
       "      <td>4.835676</td>\n",
       "      <td>9.730464</td>\n",
       "      <td>15.365492</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>54.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.350514</td>\n",
       "      <td>0.030539</td>\n",
       "      <td>0.010539</td>\n",
       "      <td>0.041078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 21:00:00</th>\n",
       "      <td>-0.100000</td>\n",
       "      <td>364</td>\n",
       "      <td>12</td>\n",
       "      <td>8734</td>\n",
       "      <td>4.832881</td>\n",
       "      <td>9.726703</td>\n",
       "      <td>15.365492</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>54.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.350514</td>\n",
       "      <td>0.030547</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>0.041093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 22:00:00</th>\n",
       "      <td>-0.250000</td>\n",
       "      <td>364</td>\n",
       "      <td>12</td>\n",
       "      <td>8735</td>\n",
       "      <td>4.830091</td>\n",
       "      <td>9.722946</td>\n",
       "      <td>15.365493</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>54.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.350514</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>0.010554</td>\n",
       "      <td>0.041108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 23:00:00</th>\n",
       "      <td>-0.983333</td>\n",
       "      <td>364</td>\n",
       "      <td>12</td>\n",
       "      <td>8736</td>\n",
       "      <td>4.827307</td>\n",
       "      <td>9.719192</td>\n",
       "      <td>15.365493</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>54.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.350514</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.041123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 00:00:00</th>\n",
       "      <td>-0.800000</td>\n",
       "      <td>365</td>\n",
       "      <td>12</td>\n",
       "      <td>8737</td>\n",
       "      <td>4.824528</td>\n",
       "      <td>9.715440</td>\n",
       "      <td>15.365493</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>54.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.350514</td>\n",
       "      <td>0.030569</td>\n",
       "      <td>0.010569</td>\n",
       "      <td>0.041138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8737 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     air_temp  dayofyear  month  hourofyear  air_temp_fit  \\\n",
       "timestamp                                                                   \n",
       "2019-01-01 00:00:00  9.100000          1      1           1      4.821755   \n",
       "2019-01-01 01:00:00  9.200000          1      1           2      4.818987   \n",
       "2019-01-01 02:00:00  9.166667          1      1           3      4.816225   \n",
       "2019-01-01 03:00:00  9.183333          1      1           4      4.813468   \n",
       "2019-01-01 04:00:00  8.916667          1      1           5      4.810717   \n",
       "...                       ...        ...    ...         ...           ...   \n",
       "2019-12-30 20:00:00  0.733333        364     12        8733      4.835676   \n",
       "2019-12-30 21:00:00 -0.100000        364     12        8734      4.832881   \n",
       "2019-12-30 22:00:00 -0.250000        364     12        8735      4.830091   \n",
       "2019-12-30 23:00:00 -0.983333        364     12        8736      4.827307   \n",
       "2019-12-31 00:00:00 -0.800000        365     12        8737      4.824528   \n",
       "\n",
       "                     ground_temp  aquifer_temp  space_heating_temp  \\\n",
       "timestamp                                                            \n",
       "2019-01-01 00:00:00     9.626282     15.365495                40.0   \n",
       "2019-01-01 01:00:00     9.622604     15.365495                40.0   \n",
       "2019-01-01 02:00:00     9.618929     15.365495                40.0   \n",
       "2019-01-01 03:00:00     9.615257     15.365495                40.0   \n",
       "2019-01-01 04:00:00     9.611587     15.365495                40.0   \n",
       "...                          ...           ...                 ...   \n",
       "2019-12-30 20:00:00     9.730464     15.365492                55.0   \n",
       "2019-12-30 21:00:00     9.726703     15.365492                55.0   \n",
       "2019-12-30 22:00:00     9.722946     15.365493                55.0   \n",
       "2019-12-30 23:00:00     9.719192     15.365493                55.0   \n",
       "2019-12-31 00:00:00     9.715440     15.365493                55.0   \n",
       "\n",
       "                     hot_water_temp  user_temp  source1_temp  source2_temp  \\\n",
       "timestamp                                                                    \n",
       "2019-01-01 00:00:00            48.0      40.16           0.0          25.0   \n",
       "2019-01-01 01:00:00            48.0      40.16           0.0          25.0   \n",
       "2019-01-01 02:00:00            48.0      40.16           0.0          25.0   \n",
       "2019-01-01 03:00:00            48.0      40.16           0.0          25.0   \n",
       "2019-01-01 04:00:00            48.0      40.16           0.0          25.0   \n",
       "...                             ...        ...           ...           ...   \n",
       "2019-12-30 20:00:00            48.0      54.79           0.0          25.0   \n",
       "2019-12-30 21:00:00            48.0      54.79           0.0          25.0   \n",
       "2019-12-30 22:00:00            48.0      54.79           0.0          25.0   \n",
       "2019-12-30 23:00:00            48.0      54.79           0.0          25.0   \n",
       "2019-12-31 00:00:00            48.0      54.79           0.0          25.0   \n",
       "\n",
       "                     net_temp       COP  E_loss_s  E_loss_r  E_loss_tot  \n",
       "timestamp                                                                \n",
       "2019-01-01 00:00:00      25.0  5.975779  0.030747  0.010747    0.041495  \n",
       "2019-01-01 01:00:00      25.0  5.975779  0.030755  0.010755    0.041510  \n",
       "2019-01-01 02:00:00      25.0  5.975779  0.030762  0.010762    0.041524  \n",
       "2019-01-01 03:00:00      25.0  5.975779  0.030769  0.010769    0.041539  \n",
       "2019-01-01 04:00:00      25.0  5.975779  0.030777  0.010777    0.041554  \n",
       "...                       ...       ...       ...       ...         ...  \n",
       "2019-12-30 20:00:00      25.0  4.350514  0.030539  0.010539    0.041078  \n",
       "2019-12-30 21:00:00      25.0  4.350514  0.030547  0.010547    0.041093  \n",
       "2019-12-30 22:00:00      25.0  4.350514  0.030554  0.010554    0.041108  \n",
       "2019-12-30 23:00:00      25.0  4.350514  0.030562  0.010562    0.041123  \n",
       "2019-12-31 00:00:00      25.0  4.350514  0.030569  0.010569    0.041138  \n",
       "\n",
       "[8737 rows x 17 columns]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tamb_hourly = AVAILABLE_DATASETS[dataset_to_work]\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Space Heating and Domestic Hot Water consumption\n",
    "\n",
    "The user determines the number of buildings and building type (single family house or small-multi family house) supplied by a district heating network. Data from the Inspire project was used to estimate the annual energy consumption for each building typology in kWh/m2-y. SFHs and MFHs correspond to reference buildings in each climatic zone built between 1945-1970, non-refurbished. \n",
    "\n",
    "The SFH and MFH models have a fixed geometry for all the climates and periods of construction. It has been defined following the common characteristics for a European buildings. The SFH building model is composed of two storeys with a total of 100 m² of living area (Inspire project, D2.1c(2014)). The small-MFH correspond to a reference residential building that has two dwellings per floor, with a total floor area of 500 m2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residential building typologies: SFH and MFH\n",
    "\n",
    "#### Single-Family units\n",
    "\n",
    "<img src=\"./images/SFH.png\">        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Families units\n",
    "\n",
    "<img src=\"./images/MFH.png\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District heating system diagram\n",
    "\n",
    "<img src=\"./images/DHC_system.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating SH, DWH and Heat Demand\n",
    "\n",
    "This calculation is based on the number of SFH ($ |SFH| $) and MFH ($ |MFH| $) units. It also depends on the total heat needed by SFH ($ TOT_{SFH} $) and MFH ($ TOT_{MFH} $) units. The formula for the Heat Demand($ HD $) is the following  \n",
    "\n",
    "\\begin{align*}\n",
    "HD = |SFH| * 100 * TOT_{SFH} + |MFH| * 500 * TOT_{MFH}\n",
    "\\end{align*}\n",
    "\n",
    "It's important to stress that this calculation is done on a year basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SFH_bldg_tot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/data-visualization-course/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SFH_bldg_tot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-2891bcb06340>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Heat_demand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_buildings_SFH\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SFH_bldg_tot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_buildings_MFH\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MFH_bldg_tot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SH_demand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Heat_demand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"%SH_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DHW_demand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Heat_demand\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"%DHW_y\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# Equivalently, we can change Tamb_hourly[\"%DHW_y\"] with (1 - Tamb_hourly[\"%SH_y\"])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data-visualization-course/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data-visualization-course/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SFH_bldg_tot'"
     ]
    }
   ],
   "source": [
    "Tamb_hourly[\"Heat_demand\"] = (n_buildings_SFH * 100 * Tamb_hourly[\"SFH_bldg_tot\"]) + (n_buildings_MFH * 500 * Tamb_hourly[\"MFH_bldg_tot\"])\n",
    "Tamb_hourly[\"SH_demand\"] = Tamb_hourly[\"Heat_demand\"] * Tamb_hourly[\"%SH_y\"]\n",
    "Tamb_hourly[\"DHW_demand\"] = Tamb_hourly[\"Heat_demand\"] * Tamb_hourly[\"%DHW_y\"] # Equivalently, we can change Tamb_hourly[\"%DHW_y\"] with (1 - Tamb_hourly[\"%SH_y\"])\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic hot water consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domestic hot water consumption is not weather influenced, and its variation is almost constant over the year. The hourly demand for hot water is estimated by the percentage of the total heat demand ($ HD_y $) is hot water $ DHW_y $. This data is obtained from the INSPIRE database for different climatic zones. In this particular case, the climatic zones and reference cities considered are:\n",
    "\n",
    "* Stuttgart, Germany for Continental climate\n",
    "* London, United Kingdom for Oceanic climate\n",
    "* Madrid, Spain for Southern-dry climate\n",
    "* Rome, Italy for Mediterranean climate\n",
    "\n",
    "The total domestic hot water demand is evenly distributed over each day of the year, and then its hourly distribution is obtained by multiplying the daily needs by an hourly random profile. \n",
    "\n",
    "\\begin{align*}\n",
    "DHW_{d} = \\frac{HD_{y}*DHW_{\\%y}}{d}\n",
    "\\end{align*}\n",
    "\n",
    "The DHW consumption is calculated in an hourly fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tamb_hourly[\"DHW_consumption\"] = Tamb_hourly[\"DHW_demand\"] * Tamb_hourly[\"DHW_hourly_consumption_ratio\"] / 365\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Space heating profile and heating degree hours\n",
    "\n",
    "The amount (in degrees) and for how long (in hours) of thermal heat required to keep the indoor building temperature at a comfortable level will vary depending on different climates. The base temperature selected was set to 15 °C.\n",
    "\n",
    "The space heating hourly profile for each location is then retrieved with a time dependency according to the heating degree method, known as the \"Integration method\".\n",
    "\n",
    "More info on calculation method: https://www.degreedays.net/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heating_degree(T_amb):\n",
    "    T_base = 15\n",
    "    return max(0, T_base - T_amb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tamb_hourly[\"heating_degree_days\"] = Tamb_hourly.air_temp.apply(heating_degree)\n",
    "Tamb_hourly[\"space_heating_dist\"] = Tamb_hourly.heating_degree_days / max(sum(Tamb_hourly.heating_degree_days), 1)\n",
    "Tamb_hourly[\"SH_consumption\"] = Tamb_hourly[\"SH_demand\"] * Tamb_hourly[\"space_heating_dist\"]\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total hourly consumption\n",
    "\n",
    "This is as easy as \n",
    "\n",
    "\\begin{align*}\n",
    "CON_{TOT} = CON_{SH} + CON_{DHW}\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tamb_hourly[\"Total_consumption\"] = Tamb_hourly[\"DHW_consumption\"] + Tamb_hourly[\"SH_consumption\"]\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SH_consumption'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/data-visualization-course/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SH_consumption'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-7a13c1cbdfba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTamb_hourly\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SH_consumption\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/data-visualization-course/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/data-visualization-course/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'SH_consumption'"
     ]
    }
   ],
   "source": [
    "Tamb_hourly[\"SH_consumption\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Calculate Space Heating and Hot Water Temperature\n",
    "\n",
    "The space Heating is calculated using a climatic curve. The Hot Water temperature is constant across the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def climatic_curve(Tamb_h):\n",
    "    Tmin_o = 2.38 #minimum outdoor T threshold in which the space heating system turns on\n",
    "    Tmax_o = 7.25 #maximum outdoor T threshold in which the space heating system turns off\n",
    "\n",
    "    if Tamb_h <= Tmin_o:   \n",
    "        Tsh = Tmax_i\n",
    "    elif Tamb_h >= Tmax_o:\n",
    "        Tsh = Tmin_i\n",
    "    else:\n",
    "        m = (Tmax_i-Tmin_i)/(Tmin_o-Tmax_o)\n",
    "        b = -m*Tmin_o+Tmax_i\n",
    "        Tsh = m*Tamb_h+b\n",
    "    return Tsh\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tamb_hourly['space_heating_temp'] = Tamb_hourly.air_temp.apply(climatic_curve)\n",
    "Tamb_hourly[\"hot_water_temp\"] = Tdhw\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate User Temperature\n",
    "\n",
    "This is the temperature that the users receive by the system. The temperature is based on their personal preferences, and the current season of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_consumption_ratio = Tamb_hourly[\"SH_consumption\"] / Tamb_hourly[\"Total_consumption\"]\n",
    "dhw_consumption_ratio = Tamb_hourly[\"DHW_consumption\"] / Tamb_hourly[\"Total_consumption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamb_hourly[\"user_temp_2\"] = Tamb_hourly.apply(Tuser, axis=1)\n",
    "Tamb_hourly[\"user_temp\"] = (sh_consumption_ratio * Tamb_hourly.space_heating_temp \n",
    "                            + dhw_consumption_ratio * Tamb_hourly.hot_water_temp)\n",
    "\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sources Temperature based on Working Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweeks = Tamb_hourly.index.dayofweek\n",
    "hours = Tamb_hourly.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tamb_hourly[\"source1_temp\"] = Ts1 * s1_schedule[hours, dayofweeks]\n",
    "Tamb_hourly[\"source2_temp\"] = Ts2 * s2_schedule[hours, dayofweeks]\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Network temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_tnet(temp_s1, temp_s2, temp_aq):\n",
    "    if temp_s1 == 0.0 and temp_s2 == 0.0:\n",
    "        return temp_aq\n",
    "    elif temp_s1 == 0.0:\n",
    "        return temp_s2\n",
    "    elif temp_s2 == 0.0:\n",
    "        return temp_s1\n",
    "    else:\n",
    "        return np.mean([temp_s1, temp_s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Tamb_hourly[\"net_temp\"] = Tamb_hourly.apply(lambda fila: calculate_tnet(fila.source1_temp, fila.source2_temp, fila.aquifer_temp), axis=1)\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient of performance (COP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_hx = 2.5\n",
    "n_HP = 0.53\n",
    "Te_o = Tamb_hourly.net_temp - DT_evap - DT_hx\n",
    "Tc_o = Tamb_hourly.user_temp\n",
    "\n",
    "Tamb_hourly['COP']= 1-n_HP + n_HP * (Tc_o + 273.15) / (Tc_o + DT_hx - Te_o)\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_losses(T_net,T_gr, DT_evap):\n",
    "    U = 2  #kW/ K \n",
    "    T_ret = T_net - DT_evap\n",
    "    HL_s = (T_net - T_gr) * U / 1000 # Heat losses supply pipe [MWh]\n",
    "    HL_r = (T_ret - T_gr) * U / 1000 # Heat losses return pipe [MWh]\n",
    "    \n",
    "    return pd.Series([HL_s, HL_r, HL_s + HL_r] , index=['E_loss_s','E_loss_r','E_loss_tot'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Tamb_hourly.apply(lambda fila: heat_losses(fila[\"net_temp\"], fila[\"ground_temp\"], DT_evap), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tamb_hourly['E_loss_s'] = x['E_loss_s']\n",
    "Tamb_hourly['E_loss_r'] = x['E_loss_r']\n",
    "Tamb_hourly['E_loss_tot'] = x['E_loss_tot']\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hourly electricity consumption by climatic zone is estimated as a function of the total thermal demand and the coefficient of performance of the systems substations:\n",
    "\n",
    "\\begin{align*}\n",
    "E_{el} = \\frac{E_{th}}{COP}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tamb_hourly['E_el']= Tamb_hourly['Total_consumption']/ Tamb_hourly['COP']\n",
    "Tamb_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermal power provided by sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user determines the maximum capacity of heat that can be recovered from the facilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save CSV version of the dataset and simulation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AVAILABLE_DATASET_PATHS = {OspitalettoDataset.OSPITALETTO: ospitaletto2019.processed_dataset_path,\n",
    "                           NOAA2010Dataset.MIAMI_FL: noaa2010Dataset.processed_miami_fl_dataset_path, \n",
    "                           NOAA2010Dataset.FRESNO_CA: noaa2010Dataset.processed_fresno_ca_dataset_path, \n",
    "                           NOAA2010Dataset.OLYMPIA_WA: noaa2010Dataset.processed_olympia_wa_dataset_path,\n",
    "                           NOAA2010Dataset.ROCHESTER_NY: noaa2010Dataset.processed_rochester_ny_dataset_path,\n",
    "                           InsPireDataset.LONDON_UK: insPireDataset.processed_london_uk_dataset_path,\n",
    "                           InsPireDataset.MADRID_SPA: insPireDataset.processed_madrid_spa_dataset_path,\n",
    "                           InsPireDataset.ROME_IT: insPireDataset.processed_rome_it_dataset_path,\n",
    "                           InsPireDataset.STUTTGART_GER: insPireDataset.processed_stuttgart_ger_dataset_path,}\n",
    "\n",
    "Tamb_hourly.to_csv(path_or_buf=AVAILABLE_DATASET_PATHS[dataset_to_work])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_values_path = os.path.join(\".\", \"data\", \"simulation_values.json\")\n",
    "\n",
    "with open(simulation_values_path, \"w\") as f:\n",
    "    json.dump(simulation_values, f, sort_keys=True, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
