{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from IPython.display import display, Math\n",
    "from scipy import optimize, stats\n",
    "from math import exp, cos, sqrt, pi, sin, sqrt, e\n",
    "\n",
    "from src.OspitalettoDataset import OspitalettoDataset\n",
    "from src.NOAA2010Dataset import NOAA2010Dataset\n",
    "from src.InsPireDataset import InsPireDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants to be used across the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT_evap': 8.0,\n",
       " 'T_base_heat_degree': 15,\n",
       " 'Tdhw': 55.0,\n",
       " 'Tmax_i': 60.0,\n",
       " 'Tmin_i': 45.0,\n",
       " 'Ts1': 23.0,\n",
       " 'Ts2': 29.0,\n",
       " 'cap_source1': 20,\n",
       " 'cap_source2': 20,\n",
       " 'depth_aquifer': 30.0,\n",
       " 'n_buildings_MFH': 1600.0,\n",
       " 'n_buildings_SFH': 0.0,\n",
       " 's1_schedule': [[0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0]],\n",
       " 's2_schedule': [[1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_values_path = os.path.join(\".\", \"data\", \"simulation_values.json\")    \n",
    "with open(simulation_values_path, \"r\") as f:\n",
    "    simulation_values = json.load(f)\n",
    "    \n",
    "simulation_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Press 1 if you want to reload previous simulation values 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Tmin_i=45.0\n",
      "* Tmax_i=60.0\n",
      "* Tdhw=55.0\n",
      "* Ts1=23.0\n",
      "* Ts2=29.0\n",
      "* DT_evap=8.0\n",
      "* n_buildings_SFH=0.0\n",
      "* n_buildings_MFH=1600.0\n",
      "* cap_source1=20\n",
      "* cap_source2=20\n",
      "* depth_aquifer=30.0\n",
      "* T_base_heat_degree=15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "load_or_write_new = int(input(\"Press 1 if you want to reload previous simulation values\"))\n",
    "\n",
    "if load_or_write_new == 1:    \n",
    "    Tmin_i = simulation_values[\"Tmin_i\"]\n",
    "    Tmax_i = simulation_values[\"Tmax_i\"]\n",
    "\n",
    "    Tdhw = simulation_values[\"Tdhw\"]\n",
    "\n",
    "    Ts1 = simulation_values[\"Ts1\"]\n",
    "    Ts2 = simulation_values[\"Ts2\"]\n",
    "\n",
    "    DT_evap = simulation_values[\"DT_evap\"]\n",
    "    \n",
    "    n_buildings_SFH = simulation_values[\"n_buildings_SFH\"]\n",
    "    n_buildings_MFH = simulation_values[\"n_buildings_MFH\"]\n",
    "    \n",
    "    cap_source1= simulation_values['cap_source1']\n",
    "    cap_source2= simulation_values['cap_source2']\n",
    "\n",
    "    depth_aquifer = simulation_values[\"depth_aquifer\"]\n",
    "    \n",
    "    T_base_heat_degree = simulation_values[\"T_base_heat_degree\"]\n",
    "    \n",
    "else:\n",
    "    # Min and Max temperatures to be received by the user.\n",
    "    # Values [40,...,60]\n",
    "    Tmin_i = float(input(\"Enter min setpoint temperature: \"))\n",
    "    Tmax_i = float(input(\"Enter max setpoint temperature: \"))\n",
    "\n",
    "    # Domestic hot water temperature.\n",
    "    # Values [45,...,55]\n",
    "    Tdhw = float(input(\"Enter domestic hot water temperature: \"))\n",
    "\n",
    "    # Our model supposes that the system has two different sources of heat.\n",
    "    # Values [20,...,30]\n",
    "    Ts1 = float(input(\"Temperature of source 1: \"))\n",
    "    Ts2 = float(input(\"Temperature of source 2: \"))\n",
    "\n",
    "    # difference in temperature between the supply (system->heat->house) and return (house -> heat -> system) pipes\n",
    "    # Values [1,...,10]\n",
    "    DT_evap = float(input(\"Temperature difference among the supply and return pipes: \"))\n",
    "    \n",
    "    # For the data visualization course, we will select 0 SFH & 1600 MFH buildings, which will cover an area of 1 km2\n",
    "    n_buildings_SFH =float(input(\"Enter the number of SFH buildings: #\"))\n",
    "    n_buildings_MFH = float(input(\"Enter the number of MFH buildings:#\"))\n",
    "    \n",
    "    cap_source1 = int(input(\"Enter the thermal capacity of source 1 in MW:\"))\n",
    "    cap_source2 = int(input(\"Enter the thermal capacity of source 2 in MW:\"))\n",
    "\n",
    "    # The depth of the aquifer in meters. Values are around 30.\n",
    "    depth_aquifer = float(input(\"Aquifer temperature depth: \"))\n",
    "    \n",
    "    T_base_heat_degree = int(input(\"Heat Degree Days base temperature: \"))\n",
    "    \n",
    "print(f\"* {Tmin_i=}\\n\"\n",
    "      f\"* {Tmax_i=}\\n\"\n",
    "      f\"* {Tdhw=}\\n\"\n",
    "      f\"* {Ts1=}\\n\"\n",
    "      f\"* {Ts2=}\\n\"\n",
    "      f\"* {DT_evap=}\\n\"\n",
    "      f\"* {n_buildings_SFH=}\\n\"\n",
    "      f\"* {n_buildings_MFH=}\\n\"\n",
    "      f\"* {cap_source1=}\\n\"\n",
    "      f\"* {cap_source2=}\\n\"\n",
    "      f\"* {depth_aquifer=}\\n\"\n",
    "      f\"* {T_base_heat_degree=}\\n\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Sources working hours\n",
    "\n",
    "The file must be a boolean matrix $W$ of $24 x 7$. The rows represent the hours in a day, and the columns represent the days in the week. For all $i \\in \\{0,...,23\\}$ and $j \\in \\{0,..., 6\\}$ we have that $w_{i,j} \\in \\{0, 1\\}$, where $w_{i,j} = 0$ means that the source doesn't produce energy at that hour $i$ on that day $j$. Similarly, $w_{i,j} = 1$ means that the source produces energy at that hour $i$ on that day $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* s1_schedule_path='./data/private/s1_source_fake_schedule.xlsx'\n",
      "* s1_schedule=array([[0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 0, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 1, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0],\n",
      "       [0, 1, 1, 1, 1, 0, 0]])\n",
      "* s1_schedule[6,1]=0\n",
      "* s1_schedule[7,1]=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s1_schedule_path = os.path.join(\".\", \"data\", \"private\", \"s1_source_fake_schedule.xlsx\")\n",
    "if load_or_write_new == 1:\n",
    "    s1_schedule = np.array(simulation_values[\"s1_schedule\"])\n",
    "else:    \n",
    "    s1_schedule = pd.read_excel(s1_schedule_path, index_col=\"Time\").to_numpy()\n",
    "\n",
    "print(f\"* {s1_schedule_path=}\\n\"\n",
    "      f\"* {s1_schedule=}\\n\"\n",
    "      f\"* {s1_schedule[6,1]=}\\n\" # Tuesdays are closed at 6 (equal to 0)\n",
    "      f\"* {s1_schedule[7,1]=}\\n\") # but open are 7 (equal to 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* s2_schedule_path='./data/private/s2_source_fake_schedule.xlsx'\n",
      "* s2_schedule=array([[1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 0, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 1, 0, 1, 1, 1, 0],\n",
      "       [1, 0, 0, 1, 1, 1, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0],\n",
      "       [1, 0, 0, 1, 1, 0, 0]])\n",
      "* s2_schedule[15,1]=1\n",
      "* s2_schedule[16,1]=0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2_schedule_path = os.path.join(\".\", \"data\", \"private\", \"s2_source_fake_schedule.xlsx\")\n",
    "if load_or_write_new == 1:\n",
    "    s2_schedule = np.array(simulation_values[\"s2_schedule\"])\n",
    "else: \n",
    "    s2_schedule = pd.read_excel(s2_schedule_path, index_col=\"Time\").to_numpy()\n",
    "\n",
    "print(f\"* {s2_schedule_path=}\\n\"\n",
    "      f\"* {s2_schedule=}\\n\"\n",
    "      f\"* {s2_schedule[15,1]=}\\n\" # Tuesdays are closed at 15 (equal to 0)\n",
    "      f\"* {s2_schedule[16,1]=}\\n\") # but open are 16 (equal to 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take note of the values for the current simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DT_evap': 8.0,\n",
       " 'T_base_heat_degree': 15,\n",
       " 'Tdhw': 55.0,\n",
       " 'Tmax_i': 60.0,\n",
       " 'Tmin_i': 45.0,\n",
       " 'Ts1': 23.0,\n",
       " 'Ts2': 29.0,\n",
       " 'cap_source1': 20,\n",
       " 'cap_source2': 20,\n",
       " 'depth_aquifer': 30.0,\n",
       " 'n_buildings_MFH': 1600.0,\n",
       " 'n_buildings_SFH': 0.0,\n",
       " 's1_schedule': [[0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 0, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 1, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0],\n",
       "  [0, 1, 1, 1, 1, 0, 0]],\n",
       " 's2_schedule': [[1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 0, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 1, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 1, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0],\n",
       "  [1, 0, 0, 1, 1, 0, 0]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_values[\"Tmin_i\"] = Tmin_i\n",
    "simulation_values[\"Tmax_i\"] = Tmax_i\n",
    "simulation_values[\"Tdhw\"] = Tdhw\n",
    "simulation_values[\"Ts1\"] = Ts1\n",
    "simulation_values[\"Ts2\"] = Ts2\n",
    "simulation_values[\"DT_evap\"] = DT_evap\n",
    "simulation_values[\"s1_schedule\"] = s1_schedule.tolist()\n",
    "simulation_values[\"s2_schedule\"] = s2_schedule.tolist()\n",
    "simulation_values[\"n_buildings_SFH\"] = n_buildings_SFH\n",
    "simulation_values[\"n_buildings_MFH\"] = n_buildings_MFH\n",
    "simulation_values['cap_source1']  = cap_source1\n",
    "simulation_values['cap_source2'] =  cap_source2\n",
    "simulation_values[\"depth_aquifer\"] = depth_aquifer\n",
    "simulation_values[\"T_base_heat_degree\"] = T_base_heat_degree\n",
    "\n",
    "simulation_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['miami_florida', 'fresno_california', 'olympia_washington', 'rochester_newyork', 'london_uk', 'madrid_spain', 'rome_italy', 'stuttgart_germany'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noaa2010Dataset = NOAA2010Dataset()\n",
    "insPireDataset = InsPireDataset()\n",
    "\n",
    "\n",
    "AVAILABLE_DATASETS = dict()\n",
    "AVAILABLE_DATASETS.update(noaa2010Dataset.load_data())\n",
    "AVAILABLE_DATASETS.update(insPireDataset.load_data())\n",
    "\n",
    "AVAILABLE_DATASETS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rome_italy'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_to_work = \"rome_italy\"\n",
    "dataset_to_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hourofyear</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>city_key</th>\n",
       "      <th>climate</th>\n",
       "      <th>DHW_cons</th>\n",
       "      <th>SH_cons</th>\n",
       "      <th>SFH_bldg_tot</th>\n",
       "      <th>MFH_bldg_tot</th>\n",
       "      <th>%SH_y</th>\n",
       "      <th>%DHW_y</th>\n",
       "      <th>DHW_hourly_consumption_ratio</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>9.100000e+06</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>9.200000e+06</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>9.166667e+06</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>9.183333e+06</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>8.916667e+06</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 20:00:00</th>\n",
       "      <td>8757</td>\n",
       "      <td>1.550000e+06</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.049895</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:00:00</th>\n",
       "      <td>8758</td>\n",
       "      <td>7.666667e+05</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>8759</td>\n",
       "      <td>2.166667e+05</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.013133</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>8760</td>\n",
       "      <td>-2.000000e+05</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>winter</td>\n",
       "      <td>2017-12-31</td>\n",
       "      <td>12</td>\n",
       "      <td>365</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.000000e+05</td>\n",
       "      <td>rome_italy</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>21.700001</td>\n",
       "      <td>75.900002</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>97.599998</td>\n",
       "      <td>0.777664</td>\n",
       "      <td>0.222336</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>winter</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8761 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hourofyear      air_temp    city_key         climate  \\\n",
       "timestamp                                                                   \n",
       "2017-01-01 00:00:00           1  9.100000e+06  rome_italy  Mediterranean    \n",
       "2017-01-01 01:00:00           2  9.200000e+06  rome_italy  Mediterranean    \n",
       "2017-01-01 02:00:00           3  9.166667e+06  rome_italy  Mediterranean    \n",
       "2017-01-01 03:00:00           4  9.183333e+06  rome_italy  Mediterranean    \n",
       "2017-01-01 04:00:00           5  8.916667e+06  rome_italy  Mediterranean    \n",
       "...                         ...           ...         ...             ...   \n",
       "2017-12-31 20:00:00        8757  1.550000e+06  rome_italy  Mediterranean    \n",
       "2017-12-31 21:00:00        8758  7.666667e+05  rome_italy  Mediterranean    \n",
       "2017-12-31 22:00:00        8759  2.166667e+05  rome_italy  Mediterranean    \n",
       "2017-12-31 23:00:00        8760 -2.000000e+05  rome_italy  Mediterranean    \n",
       "2018-01-01 00:00:00           1 -2.000000e+05  rome_italy  Mediterranean    \n",
       "\n",
       "                      DHW_cons    SH_cons  SFH_bldg_tot  MFH_bldg_tot  \\\n",
       "timestamp                                                               \n",
       "2017-01-01 00:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2017-01-01 01:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2017-01-01 02:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2017-01-01 03:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2017-01-01 04:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "...                        ...        ...           ...           ...   \n",
       "2017-12-31 20:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2017-12-31 21:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2017-12-31 22:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2017-12-31 23:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "2018-01-01 00:00:00  21.700001  75.900002     97.599998     97.599998   \n",
       "\n",
       "                        %SH_y    %DHW_y  DHW_hourly_consumption_ratio  season  \\\n",
       "timestamp                                                                       \n",
       "2017-01-01 00:00:00  0.777664  0.222336                      0.003885  winter   \n",
       "2017-01-01 01:00:00  0.777664  0.222336                      0.003885  winter   \n",
       "2017-01-01 02:00:00  0.777664  0.222336                      0.003885  winter   \n",
       "2017-01-01 03:00:00  0.777664  0.222336                      0.003885  winter   \n",
       "2017-01-01 04:00:00  0.777664  0.222336                      0.003885  winter   \n",
       "...                       ...       ...                           ...     ...   \n",
       "2017-12-31 20:00:00  0.777664  0.222336                      0.049895  winter   \n",
       "2017-12-31 21:00:00  0.777664  0.222336                      0.006780  winter   \n",
       "2017-12-31 22:00:00  0.777664  0.222336                      0.013133  winter   \n",
       "2017-12-31 23:00:00  0.777664  0.222336                      0.003885  winter   \n",
       "2018-01-01 00:00:00  0.777664  0.222336                      0.003885  winter   \n",
       "\n",
       "                           date  month  dayofyear  dayofweek  hour  \n",
       "timestamp                                                           \n",
       "2017-01-01 00:00:00  2017-01-01      1          1          6     0  \n",
       "2017-01-01 01:00:00  2017-01-01      1          1          6     1  \n",
       "2017-01-01 02:00:00  2017-01-01      1          1          6     2  \n",
       "2017-01-01 03:00:00  2017-01-01      1          1          6     3  \n",
       "2017-01-01 04:00:00  2017-01-01      1          1          6     4  \n",
       "...                         ...    ...        ...        ...   ...  \n",
       "2017-12-31 20:00:00  2017-12-31     12        365          6    20  \n",
       "2017-12-31 21:00:00  2017-12-31     12        365          6    21  \n",
       "2017-12-31 22:00:00  2017-12-31     12        365          6    22  \n",
       "2017-12-31 23:00:00  2017-12-31     12        365          6    23  \n",
       "2018-01-01 00:00:00  2018-01-01      1          1          0     0  \n",
       "\n",
       "[8761 rows x 17 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = AVAILABLE_DATASETS[dataset_to_work]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the dataset-related constants\n",
    "\n",
    "- `T_daily_a`: Average air temperature on a daily basis. \n",
    "- `DT_y`: Difference between the maximum daily temperature and the mean daily temperature.\n",
    "- `d_shift_min`: Day of the year with the min read temperature.\n",
    "- `d_shift_max`: Day of the year with the max read temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* dataset=                     hourofyear  air_temp    city_key         climate  \\\n",
      "timestamp                                                               \n",
      "2017-01-01 00:00:00           1      7.00  rome_italy  Mediterranean    \n",
      "2017-01-01 01:00:00           2      9.50  rome_italy  Mediterranean    \n",
      "2017-01-01 02:00:00           3     11.70  rome_italy  Mediterranean    \n",
      "2017-01-01 03:00:00           4     11.15  rome_italy  Mediterranean    \n",
      "2017-01-01 04:00:00           5     10.75  rome_italy  Mediterranean    \n",
      "...                         ...       ...         ...             ...   \n",
      "2017-12-31 20:00:00        8757     10.15  rome_italy  Mediterranean    \n",
      "2017-12-31 21:00:00        8758      9.45  rome_italy  Mediterranean    \n",
      "2017-12-31 22:00:00        8759      8.75  rome_italy  Mediterranean    \n",
      "2017-12-31 23:00:00        8760      8.00  rome_italy  Mediterranean    \n",
      "2018-01-01 00:00:00           1      7.30  rome_italy  Mediterranean    \n",
      "\n",
      "                      DHW_cons    SH_cons  SFH_bldg_tot  MFH_bldg_tot  \\\n",
      "timestamp                                                               \n",
      "2017-01-01 00:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2017-01-01 01:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2017-01-01 02:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2017-01-01 03:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2017-01-01 04:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "...                        ...        ...           ...           ...   \n",
      "2017-12-31 20:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2017-12-31 21:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2017-12-31 22:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2017-12-31 23:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "2018-01-01 00:00:00  21.700001  75.900002     97.599998     97.599998   \n",
      "\n",
      "                        %SH_y    %DHW_y  DHW_hourly_consumption_ratio  season  \\\n",
      "timestamp                                                                       \n",
      "2017-01-01 00:00:00  0.777664  0.222336                      0.003885  winter   \n",
      "2017-01-01 01:00:00  0.777664  0.222336                      0.003885  winter   \n",
      "2017-01-01 02:00:00  0.777664  0.222336                      0.003885  winter   \n",
      "2017-01-01 03:00:00  0.777664  0.222336                      0.003885  winter   \n",
      "2017-01-01 04:00:00  0.777664  0.222336                      0.003885  winter   \n",
      "...                       ...       ...                           ...     ...   \n",
      "2017-12-31 20:00:00  0.777664  0.222336                      0.049895  winter   \n",
      "2017-12-31 21:00:00  0.777664  0.222336                      0.006780  winter   \n",
      "2017-12-31 22:00:00  0.777664  0.222336                      0.013133  winter   \n",
      "2017-12-31 23:00:00  0.777664  0.222336                      0.003885  winter   \n",
      "2018-01-01 00:00:00  0.777664  0.222336                      0.003885  winter   \n",
      "\n",
      "                           date  month  dayofyear  dayofweek  hour  \n",
      "timestamp                                                           \n",
      "2017-01-01 00:00:00  2017-01-01      1          1          6     0  \n",
      "2017-01-01 01:00:00  2017-01-01      1          1          6     1  \n",
      "2017-01-01 02:00:00  2017-01-01      1          1          6     2  \n",
      "2017-01-01 03:00:00  2017-01-01      1          1          6     3  \n",
      "2017-01-01 04:00:00  2017-01-01      1          1          6     4  \n",
      "...                         ...    ...        ...        ...   ...  \n",
      "2017-12-31 20:00:00  2017-12-31     12        365          6    20  \n",
      "2017-12-31 21:00:00  2017-12-31     12        365          6    21  \n",
      "2017-12-31 22:00:00  2017-12-31     12        365          6    22  \n",
      "2017-12-31 23:00:00  2017-12-31     12        365          6    23  \n",
      "2018-01-01 00:00:00  2018-01-01      1          1          0     0  \n",
      "\n",
      "[8761 rows x 17 columns]\n",
      "* T_daily_avg=             air_temp  dayofyear  month  hourofyear\n",
      "timestamp                                          \n",
      "2017-01-01  13.102083          1      1           1\n",
      "2017-01-02  11.239583          2      1          25\n",
      "2017-01-03  11.777083          3      1          49\n",
      "2017-01-04   8.860416          4      1          73\n",
      "2017-01-05   8.039583          5      1          97\n",
      "...               ...        ...    ...         ...\n",
      "2017-12-28   6.802083        362     12        8665\n",
      "2017-12-29  10.064584        363     12        8689\n",
      "2017-12-30  11.712500        364     12        8713\n",
      "2017-12-31  10.225000        365     12        8737\n",
      "2018-01-01   7.300000          1      1           1\n",
      "\n",
      "[366 rows x 4 columns]\n",
      "* T_ave_h=15.81152629852295\n",
      "* DT_y=12.005141258239746\n",
      "* d_shift_min=12\n",
      "* T_daily_avg.air_temp.min()=2.0916666984558105\n",
      "* d_shift_max=231\n",
      "* T_daily_avg.air_temp.max()=27.816667556762695\n",
      "* t=timestamp\n",
      "2017-01-01      1\n",
      "2017-01-02      2\n",
      "2017-01-03      3\n",
      "2017-01-04      4\n",
      "2017-01-05      5\n",
      "             ... \n",
      "2017-12-28    362\n",
      "2017-12-29    363\n",
      "2017-12-30    364\n",
      "2017-12-31    365\n",
      "2018-01-01      1\n",
      "Freq: D, Name: dayofyear, Length: 366, dtype: int64\n",
      "* num_hours=8761\n",
      "* h=timestamp\n",
      "2017-01-01 00:00:00       1\n",
      "2017-01-01 01:00:00       2\n",
      "2017-01-01 02:00:00       3\n",
      "2017-01-01 03:00:00       4\n",
      "2017-01-01 04:00:00       5\n",
      "                       ... \n",
      "2017-12-31 20:00:00    8757\n",
      "2017-12-31 21:00:00    8758\n",
      "2017-12-31 22:00:00    8759\n",
      "2017-12-31 23:00:00    8760\n",
      "2018-01-01 00:00:00       1\n",
      "Name: hourofyear, Length: 8761, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a daily dataset\n",
    "T_daily_avg = dataset[\"air_temp\"].resample('D').mean().to_frame()\n",
    "T_daily_avg[\"dayofyear\"] = T_daily_avg.index.dayofyear\n",
    "T_daily_avg[\"month\"] = T_daily_avg.index.month\n",
    "T_daily_avg[\"hourofyear\"] = (T_daily_avg.index.dayofyear - 1) * 24 + (T_daily_avg.index.hour + 1)\n",
    "\n",
    "T_ave_h = T_daily_avg.air_temp.mean()\n",
    "T_max = T_daily_avg.air_temp.max()\n",
    "DT_y = T_max - T_ave_h\n",
    "\n",
    "d_shift_min = T_daily_avg.air_temp.idxmin(axis=0).dayofyear #Day of the min Temperature\n",
    "d_shift_max = T_daily_avg.air_temp.idxmax(axis=0).dayofyear #Day of the max Temperature\n",
    "\n",
    "t = T_daily_avg.dayofyear\n",
    "\n",
    "num_hours = dataset.shape[0] # Number of hours in a year = 8737 hrs\n",
    "h = dataset.hourofyear # A range equivalent to the hours of the year from 1 to 8761\n",
    "\n",
    "print(f\"* {dataset=}\\n\"\n",
    "      f\"* {T_daily_avg=}\\n\"\n",
    "      f\"* {T_ave_h=}\\n\"\n",
    "      f\"* {DT_y=}\\n\"\n",
    "      f\"* {d_shift_min=}\\n\"\n",
    "      f\"* {T_daily_avg.air_temp.min()=}\\n\"\n",
    "      f\"* {d_shift_max=}\\n\"\n",
    "      f\"* {T_daily_avg.air_temp.max()=}\\n\"\n",
    "      f\"* {t=}\\n\"\n",
    "      f\"* {num_hours=}\\n\"\n",
    "      f\"* {h=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional unit composition\n",
    "\n",
    "The single-family houses (SFH) and multi-family houses (MFH) models have a fixed geometry for all the climates and periods of construction. It has been defined following the common characteristics for a European buildings. The SFH building model is composed of two storeys with a total of 100 m² of living area . The small-MFH correspond to a reference residential building that has two dwellings per floor, with a total floor area of 500 m2. (Inspire project, D2.1c(2014))\n",
    "\n",
    "A functional unit of 1 km2 of land composed by a residential area of 1600 buildings of the type small-MFH was selected. This reference area has been already investigated in previous publications for the scenario assessment of low-temperature DH networks, as a typical high-density urban zone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residential building typologies: SFH and MFH\n",
    "\n",
    "#### Single-Family units\n",
    "\n",
    "![SFH](images/SFH.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Families units\n",
    "\n",
    "![s-MFH](images/MFH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### District heating system diagram\n",
    "\n",
    "District heating (DH) is an energy service based on moving heat from available heat sources to immediate customers through a piping network. Nowadays, the fundamental idea of DH is to use LOCAL sources that would otherwise be WASTED in order to satisfy customers'needs (Werner, 2013). \n",
    "\n",
    "\n",
    "Traditional DH systems operate typically at temperatures far from the ambient temperature (80°C or higher) giving rise to high thermal losses and the need of costly piping insulation. Examples of traditional DH sources are cogeneration plants, industrial waste heat and incinerators, where heat is a by-product of other industrial processes (Cozzini, 2018).\n",
    "\n",
    "New concepts in the DH sector propose lowering the operating temperatures further to a level equivalent to the ambient temperature, with an average of 20°C. Advantages of a system of this kind, are the reduction in thermal losses in the distribution system, the direct exploitation of available waste heat sources (refrigeration units in shopping malls, supermarkets, datacenters) and ground sources (aquifer wells), and the possibility of providing not only heating but also cooling through the use of reversible heat pumps on the buildings substations, as presented in the Figure.\n",
    "\n",
    "![DHC system](images/DHC_system.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Data Processing for Space Heating Demand and Domestic Hot Water\n",
    "\n",
    "The methodology used in this project is a bottom-up approach for the calculation of the total heat demand for space heating (SH) and domestic hot water (DHW) utilization of a district located in 4 different climates across Europe, using data from the Inspire project. The data includes annual energy consumption for each building typology in kWh/m2-y, SFHs and MFHs correspond to reference buildings in each climatic zone built between 1945-1970, non-refurbished. In this particular case, the climatic zones and reference cities considered are:\n",
    "\n",
    "* Stuttgart, Germany for Continental climate\n",
    "* London, United Kingdom for Oceanic climate\n",
    "* Madrid, Spain for Southern-dry climate\n",
    "* Rome, Italy for Mediterranean climate\n",
    "\n",
    "This calculation is based on the number of SFH ($ |SFH| $) and MFH ($ |MFH| $) units. It also depends on the total heat needed by SFH ($ TOT_{SFH}$) and MFH ($ TOT_{MFH}$) units. The estimation of the total heated area for buildings within the functional unit ($ HD $) is:\n",
    "\n",
    "\\begin{align*}\n",
    "HD = |SFH| * 100 * TOT_{SFH} + |MFH| * 500 * TOT_{MFH}\n",
    "\\end{align*}\n",
    "\n",
    "It's important to stress that this calculation is done on a year basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Heat_demand\"] = (n_buildings_SFH * 100 * dataset[\"SFH_bldg_tot\"]) + (n_buildings_MFH * 500 * dataset[\"MFH_bldg_tot\"])\n",
    "dataset[\"SH_demand\"] = dataset[\"Heat_demand\"] * dataset[\"%SH_y\"]\n",
    "dataset[\"DHW_demand\"] = dataset[\"Heat_demand\"] * dataset[\"%DHW_y\"] # Equivalently, we can change dataset[\"%DHW_y\"] with (1 - dataset[\"%SH_y\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Space Heating Profile Distribution\n",
    "\n",
    "In order to analyse the performance of this particular DH system, it is fundamental not only the spatial distribution of the heat demand, but also the distribution over time. For this purpose, the space heating hourly profile for each location is retrieved with a time dependency according to the heating degree method, known as the \"Integration method\".\n",
    "\n",
    "This method accounts the amount (in degrees) and for how long (in hours) thermal heat is required to keep the indoor building temperature at a comfortable level, which will vary depending on different climates. The base temperature selected was set to 15 °C.\n",
    "\n",
    "More info on calculation method: https://www.degreedays.net/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heating_degree(T_amb):\n",
    "    return max(0, T_base_heat_degree - T_amb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"heating_degree_days\"] = dataset.air_temp.apply(heating_degree)\n",
    "dataset[\"space_heating_dist\"] = dataset.heating_degree_days / max(sum(dataset.heating_degree_days), 1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Space Heating Consumption (H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"SH_consumption\"] = dataset[\"SH_demand\"] * dataset[\"space_heating_dist\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Domestic Hot Water Consumption (H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domestic hot water consumption is not weather influenced, and its variation is almost constant over the year. The hourly demand for hot water is estimated by the percentage of the total heat demand ($ HD_y $) is hot water $ DHW_y $. This data is also obtained from the INSPIRE database for different climatic zones. \n",
    "\n",
    "The total domestic hot water demand is evenly distributed over each day of the year, and then its hourly distribution is obtained by multiplying the daily needs by an hourly random profile. \n",
    "\n",
    "\\begin{align*}\n",
    "DHW_{d} = \\frac{HD_{y}*DHW_{\\%y}}{d}\n",
    "\\end{align*}\n",
    "\n",
    "The DHW consumption is calculated in an hourly fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"DHW_consumption\"] = dataset[\"DHW_demand\"] * dataset[\"DHW_hourly_consumption_ratio\"] / 365\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Thermal Load Profile (H) \n",
    "\n",
    "Thus, the aggregated heat demand corresponds to the sum of the thermal heat requirements for SH and DHW, according to the equation:\n",
    "\n",
    "\\begin{align*}\n",
    "HD_{TOT, h} = HD_{SH, h} + HD_{DHW, h}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Total_consumption\"] = dataset[\"DHW_consumption\"] + dataset[\"SH_consumption\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Adjusting the total consumption by air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Total_consumption_fit\"] = np.nan\n",
    "\n",
    "records_with_heat_degree_days = dataset[dataset.air_temp <= T_base_heat_degree]\n",
    "if records_with_heat_degree_days.shape[0] == 0:\n",
    "    print(f\"Key {dataset_to_work} has no degree days.\")\n",
    "else:\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(records_with_heat_degree_days.air_temp, records_with_heat_degree_days.Total_consumption)\n",
    "    dataset[\"Total_consumption_fit\"] = slope * records_with_heat_degree_days.air_temp + intercept\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Climate Curve (H)\n",
    "\n",
    "Temperature levels required for SH and DHW. The space Heating is calculated using a climatic curve. The Hot Water temperature is constant across the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def climatic_curve(Tamb_h):\n",
    "    Tmin_o = 2.38 #minimum outdoor T threshold in which the space heating system turns on\n",
    "    Tmax_o = 7.25 #maximum outdoor T threshold in which the space heating system turns off\n",
    "\n",
    "    if Tamb_h <= Tmin_o:   \n",
    "        Tsh = Tmax_i\n",
    "    elif Tamb_h >= Tmax_o:\n",
    "        Tsh = Tmin_i\n",
    "    else:\n",
    "        m = (Tmax_i-Tmin_i)/(Tmin_o-Tmax_o)\n",
    "        b = -m*Tmin_o+Tmax_i\n",
    "        Tsh = m*Tamb_h+b\n",
    "    return Tsh\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['space_heating_temp'] = dataset.air_temp.apply(climatic_curve)\n",
    "dataset[\"hot_water_temp\"] = Tdhw\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 User Temperature Level (H)\n",
    "\n",
    "This is the temperature that the users receive by the system. The temperature is based on their personal preferences, and the current season of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh_consumption_ratio = dataset[\"SH_consumption\"] / dataset[\"Total_consumption\"]\n",
    "dhw_consumption_ratio = dataset[\"DHW_consumption\"] / dataset[\"Total_consumption\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"user_temp\"] = (sh_consumption_ratio * dataset.space_heating_temp \n",
    "                        + dhw_consumption_ratio * dataset.hot_water_temp)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Fitting Curve (H)\n",
    "\n",
    "For more info visit the [scipy.optimize.curve_fit docs](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html#scipy.optimize.curve_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def func(x, disp, amp, phi):\n",
    "    t0 = len(h) # hourly resolution if x is in hours\n",
    "    omega = 2 * pi / t0\n",
    "    return disp + amp * np.cos(x * omega - phi)\n",
    "\n",
    "x_data = pd.Series(range(0,len(dataset)))\n",
    "y_data = dataset.air_temp\n",
    "params, params_covariance = optimize.curve_fit(func, x_data, y_data, p0=[T_ave_h, DT_y, d_shift_max * 24])\n",
    "print(f\"* {params=}\\n\"\n",
    "      f\"* {params_covariance=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "T_ave_fit = params[0]\n",
    "DT_y_fit = params[1]\n",
    "phi = params[2] #Corresponds to day 202\n",
    "\n",
    "#'displacement, amplitude, and phase of the signal\n",
    "print('Fitted parameters:')\n",
    "display(Math(f\"dist={T_ave_fit:.2f}, amp={DT_y_fit:.2f}, \\\\phi={phi:.2f}\"))\n",
    "\n",
    "print('Original parameters:')\n",
    "display(Math(f\"dist={T_ave_h:.2f}, amp={DT_y:.2f}, \\\\phi={d_shift_max*24:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Calculate the fitting curve\n",
    "\n",
    "Using the fitted parameters we can calculate the fitted air temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fitting_curve(hourofyear, T_ave_fit, DT_y_fit, T, phi, pi):\n",
    "    omega = 2 * pi / T\n",
    "    return T_ave_fit + DT_y_fit * np.cos(hourofyear * omega - phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "T = dataset.hourofyear.shape[0]\n",
    "dataset[\"air_temp_fit\"] = dataset.hourofyear.apply(fitting_curve, args=(T_ave_fit, DT_y_fit, T, phi, pi))\n",
    "\n",
    "d_shift_min = dataset.air_temp_fit.idxmin(axis=0)\n",
    "d_shift_max = dataset.air_temp_fit.idxmax(axis=0)\n",
    "\n",
    "dd_min = dataset[dataset.index == d_shift_min].dayofyear.item() # d_shift_min / 24\n",
    "dd_max = dataset[dataset.index == d_shift_max].dayofyear.item() # d_shift_max / 24\n",
    "\n",
    "print(f'* {T=}\\n'\n",
    "      f'* {dataset[[\"air_temp_fit\"]]=}\\n'\n",
    "      f'* d_min (h): {d_shift_min}\\n'\n",
    "      f'* day_number: {dd_min}\\n'\n",
    "      f'* d_max (h): {d_shift_max}\\n'\n",
    "      f'* day_number: {dd_max}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Ground temperature\n",
    "\n",
    "The ground temperature is calculated as a function of the ambient temperature fitting curve using the Kusuda equation, ref: \n",
    "- [Measurements of Ground Temperature at Various Depths](https://www.researchgate.net/publication/30500372_Measurements_of_Ground_Temperature_at_Various_Depths?enrichId=rgreq-e2031a024b742c0018bb428dca3100f5-XXX&enrichSource=Y292ZXJQYWdlOzMwNTAwMzcyO0FTOjEwMTI0NTIzNDcxMjU4M0AxNDAxMTUwMTUzNjYy&el=1_x_2&_esc=publicationCoverPdf)\n",
    "- [Earth Temperatures and Thermal Diffusivity at Selected Stations in the United States](https://nvlpubs.nist.gov/nistpubs/Legacy/RPT/nbsreport8972.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "zz = 1 # Depth [m]\n",
    "alpha = 0.06048 # Ground thermal diffusivity, Banks [m^2/day]\n",
    "alpha_sec = 7e-7 # Ground thermal diffusivity, Banks [m^2/s]\n",
    "t_sec = 365 * 24 * 3600 # Number of seconds in a year.\n",
    "\n",
    "t_0 = T_daily_avg.shape[0] # Number of days in a year =365 days\n",
    "\n",
    "Tg_und = T_ave_fit # Undisturbed ground temperature\n",
    "DT_y = abs(DT_y_fit)\n",
    "\n",
    "print(f\"* {zz=}\\n\"\n",
    "      f\"* {alpha=}\\n\"\n",
    "      f\"* {alpha_sec=}\\n\"\n",
    "      f\"* {t_sec=}\\n\"\n",
    "      f\"* {t_0=}\\n\"\n",
    "      f\"* {Tg_und=}\\n\"\n",
    "      f\"* {DT_y=}\\n\"\n",
    "      f\"* {dd_min=}\\n\"\n",
    "      f\"* {dd_max=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ground_temperature_hour(t: int):\n",
    "    #t is time in hours, but the calculation is done is seconds\n",
    "    kusuda = Tg_und - DT_y*exp(-zz*sqrt(pi/(alpha_sec*t_sec))) *cos(2*pi/t_sec*((t-dd_min*24)*3600-zz/2*sqrt(t_sec/(pi*alpha_sec)))) #Kusuda\n",
    "    return pd.Series({'T_kusuda': kusuda})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"ground_temp\"] = dataset.hourofyear.apply(ground_temperature_hour)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Aquifer Well Temperature (Y)\n",
    "\n",
    "We use the same equation (Kusuda) to calculate the temperature of an aquifer well located `depth_aquifer` meters depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "zz = depth_aquifer\n",
    "\n",
    "print(f\"* {zz=}\\n\"\n",
    "      f\"* {alpha=}\\n\"\n",
    "      f\"* {alpha_sec=}\\n\"\n",
    "      f\"* {t_sec=}\\n\"\n",
    "      f\"* {t_0=}\\n\"\n",
    "      f\"* {Tg_und=}\\n\"\n",
    "      f\"* {DT_y=}\\n\"\n",
    "      f\"* {dd_min=}\\n\"\n",
    "      f\"* {dd_max=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"aquifer_temp\"] = dataset.hourofyear.apply(ground_temperature_hour)\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10 Network temperature (H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.1 Calculate Sources Temperature based on Working Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweeks = dataset.index.dayofweek\n",
    "hours = dataset.index.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"source1_temp\"] = Ts1 * s1_schedule[hours, dayofweeks]\n",
    "dataset[\"source2_temp\"] = Ts2 * s2_schedule[hours, dayofweeks]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10.2 Calculate Network Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_tnet(temp_s1, temp_s2, temp_aq):\n",
    "    if temp_s1 == 0.0 and temp_s2 == 0.0:\n",
    "        return temp_aq\n",
    "    elif temp_s1 == 0.0:\n",
    "        return temp_s2\n",
    "    elif temp_s2 == 0.0:\n",
    "        return temp_s1\n",
    "    else:\n",
    "        return np.min([temp_s1, temp_s2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"net_temp\"] = dataset.apply(lambda fila: calculate_tnet(fila.source1_temp, fila.source2_temp, fila.aquifer_temp), axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.11 Coefficient of performance (COP)\n",
    "\n",
    "Heat pumps located at the users' substations are responsible for lifting the network temperature to a desired level for SH and DHW consumptions. The performance of the overall system was assessed according to the following coefficient of performance (COP) function:\n",
    "\n",
    "\\begin{equation}\n",
    "COP\\ = \\eta_{m} COP_{C} +1 - \\eta_{m}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "COP_{C}= \\frac{T_{c}}{T{_c} - T_{e}} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "T_{c}= T_{c,o} +  \\Delta T_{HEX} \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "T_{e}=  T_{e,o} -  \\Delta T_{HEX} \n",
    "\\end{equation}\n",
    "\n",
    "Where $COP_{C}$ corresponds to the Carnot COP which is a function of the condenser ($ T_{c}$) and evaporator ($T_{e}$) refrigerant temperatures respectively. These variables are estimated as the external fluid outlet temperatures, adjusted by a temperature drop ($\\Delta T_{HEX}$) at the heat pump condenser and evaporator.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_hx = 2.5\n",
    "n_HP = 0.53\n",
    "Te_o = dataset.net_temp - DT_evap - DT_hx\n",
    "Tc_o = dataset.user_temp\n",
    "\n",
    "dataset['COP'] = 1 - n_HP + n_HP * (Tc_o + 273.15) / (Tc_o + DT_hx - Te_o)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.12 Heat losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_losses(T_net,T_gr, DT_evap):\n",
    "    U = 0.848  #Average heat loss of pre-insulated pipes along a network of 2km [MW/ K] \n",
    "    T_ret = T_net - DT_evap\n",
    "    HL_s = (T_net - T_gr) * U  # Heat losses supply pipe [MW]\n",
    "    HL_r = (T_ret - T_gr) * U  # Heat losses return pipe [MW]\n",
    "    \n",
    "    return pd.Series([HL_s, HL_r, HL_s + HL_r] , index=['E_loss_s','E_loss_r','E_loss_tot'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['E_loss_s', 'E_loss_r', 'E_loss_tot']] = dataset.apply(lambda fila: heat_losses(fila[\"net_temp\"], fila[\"ground_temp\"], DT_evap), axis=1, result_type='expand')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.13 Electricity consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hourly electricity consumption by climatic zone is estimated as a function of the total thermal demand and the coefficient of performance of the systems substations:\n",
    "\n",
    "\\begin{align*}\n",
    "E_{el} = \\frac{E_{th}}{COP}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['E_el'] = dataset['Total_consumption'] / dataset['COP']\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.14 Thermal Energy from Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District heating systems have an opportunity to use heat supply from several sources at the same time. In order for this to happen, it is necessary a control system that allows many thermal plants to deliver heat at the same distribution system. In this case, the base load can be supplied by up to two sources of waste heat, with a maximum capacity and temperature levels determined by the user of this tool. A third source consisting in aquifer wells provides heat from a depth of about 30 m when the base load plants are not operating, as well as in peak load conditions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"source1_cap\"] = cap_source1 * 1000 * s1_schedule[hours, dayofweeks] # values in kW to match the thermal demand calculations\n",
    "dataset[\"source2_cap\"] = cap_source2 * 1000 *  s2_schedule[hours, dayofweeks] # values in kW to match the thermal demand calculations\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_heatsupply(source1_cap, source2_cap, source1_temp, source2_temp,thermal_energy_from_sources):\n",
    "    if source1_cap == 0.0 and source2_cap == 0.0:\n",
    "        heat_source1 = 0.0\n",
    "        heat_source2= 0.0\n",
    "        heat_aquifer = thermal_energy_from_sources\n",
    "        return pd.Series([heat_source1, heat_source2, heat_aquifer] , index=['heat_source1','heat_source2','heat_aquifer'])    \n",
    "    elif source1_cap == 0.0:                    #Si la primera fuente no funciona, la otra cubre la demanda hasta su max capacidad\n",
    "        if thermal_energy_from_sources <=  source2_cap:\n",
    "            heat_source1 = 0.0\n",
    "            heat_source2 = thermal_energy_from_sources\n",
    "            heat_aquifer = 0.0\n",
    "        else:\n",
    "            heat_source1 = 0.0\n",
    "            heat_source2 = source2_cap\n",
    "            heat_aquifer = thermal_energy_from_sources - source2_cap\n",
    "        return pd.Series([heat_source1, heat_source2, heat_aquifer] , index=['heat_source1','heat_source2','heat_aquifer'])    \n",
    "    elif source2_cap == 0.0:                                 #Si la segunda fuente no funciona, la otra cubre la demanda hasta su max capacidad\n",
    "        if thermal_energy_from_sources <=  source1_cap:\n",
    "            heat_source1 = thermal_energy_from_sources\n",
    "            heat_source2 = 0.0\n",
    "            heat_aquifer = 0.0\n",
    "        else:\n",
    "            heat_source1 = source1_cap\n",
    "            heat_source2 = 0.0\n",
    "            heat_aquifer = thermal_energy_from_sources - source1_cap\n",
    "        return pd.Series([heat_source1, heat_source2, heat_aquifer] , index=['heat_source1','heat_source2','heat_aquifer'])    \n",
    "    else:                            #Si ambas plantas funcionan, opera la de mayor temperatura hasta su max capacidad, si no es suficiente, se activa la segunda planta\n",
    "        if source1_temp < source2_temp:\n",
    "            \n",
    "            if thermal_energy_from_sources <=  source1_cap:\n",
    "                heat_source1 = thermal_energy_from_sources\n",
    "                heat_source2 = 0.0\n",
    "                heat_aquifer = 0.0\n",
    "            else:\n",
    "                heat_source1 = source1_cap\n",
    "                heat_source2 = thermal_energy_from_sources - source1_cap\n",
    "                heat_aquifer = 0.0\n",
    "            \n",
    "            return pd.Series([heat_source1, heat_source2, heat_aquifer] , index=['heat_source1','heat_source2','heat_aquifer'])           \n",
    "        else: \n",
    "            if thermal_energy_from_sources <=  source2_cap:\n",
    "                heat_source1 = 0.0\n",
    "                heat_source2 = thermal_energy_from_sources\n",
    "                heat_aquifer = 0.0\n",
    "            else:\n",
    "                heat_source1 = thermal_energy_from_sources - source2_cap\n",
    "                heat_source2 = source2_cap\n",
    "                heat_aquifer = 0.0\n",
    "            return pd.Series([heat_source1, heat_source2, heat_aquifer] , index=['heat_source1','heat_source2','heat_aquifer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[[\"heat_source1\", \"heat_source2\", \"heat_aquifer\"]] = dataset.apply(lambda fila: calculate_heatsupply(fila.source1_cap,fila.source2_cap, fila.source1_temp, fila.source2_temp, fila.Total_consumption - fila.E_el), axis=1 , result_type='expand')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save CSV version of the dataset and simulation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "AVAILABLE_DATASET_PATHS = {NOAA2010Dataset.MIAMI_FL: noaa2010Dataset.processed_miami_fl_dataset_path, \n",
    "                           NOAA2010Dataset.FRESNO_CA: noaa2010Dataset.processed_fresno_ca_dataset_path, \n",
    "                           NOAA2010Dataset.OLYMPIA_WA: noaa2010Dataset.processed_olympia_wa_dataset_path,\n",
    "                           NOAA2010Dataset.ROCHESTER_NY: noaa2010Dataset.processed_rochester_ny_dataset_path,\n",
    "                           InsPireDataset.LONDON_UK: insPireDataset.processed_london_uk_dataset_path,\n",
    "                           InsPireDataset.MADRID_SPA: insPireDataset.processed_madrid_spa_dataset_path,\n",
    "                           InsPireDataset.ROME_IT: insPireDataset.processed_rome_it_dataset_path,\n",
    "                           InsPireDataset.STUTTGART_GER: insPireDataset.processed_stuttgart_ger_dataset_path,}\n",
    "\n",
    "dataset.to_csv(path_or_buf=f\"{AVAILABLE_DATASET_PATHS[dataset_to_work]}.csv\")\n",
    "dataset.to_parquet(path=f\"{AVAILABLE_DATASET_PATHS[dataset_to_work]}.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_values_path = os.path.join(\".\", \"data\", \"simulation_values.json\")\n",
    "\n",
    "with open(simulation_values_path, \"w\") as f:\n",
    "    json.dump(simulation_values, f, sort_keys=True, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
